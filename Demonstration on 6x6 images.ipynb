{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration on 6x6 images\n",
    "\n",
    "Important: The current code I'm using has moved into [toysamples1.py](toysamples1.py) for now, because displaying the output images here was eating up too much web browser memory.  It might move back at some point, since I could simply run that code from here, now that the images are now saved to files; and then just display images I want there.  But then, that would seem to negate a lot of the advantages of jupyter.  Anyway, we shall see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.random.choice(2, size=(4,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "num_classes = 4\n",
    "image_size = 6\n",
    "N = 100\n",
    "num_samples_to_print = 7\n",
    "sigma_X = 0.01\n",
    "\n",
    "class_descriptions = [\n",
    "    {\n",
    "        'sprite': [\n",
    "            [0,1,0],\n",
    "            [1,1,1],\n",
    "            [0,1,0]\n",
    "        ],\n",
    "        'sprite_x': 0,\n",
    "        'sprite_y': 0\n",
    "    },\n",
    "    {\n",
    "        'sprite': [\n",
    "            [1,1,1],\n",
    "            [1,0,1],\n",
    "            [1,1,1]\n",
    "        ],\n",
    "        'sprite_x': 3,\n",
    "        'sprite_y': 0\n",
    "    },\n",
    "    {\n",
    "        'sprite': [\n",
    "            [1,0,0],\n",
    "            [1,1,0],\n",
    "            [1,1,1]\n",
    "        ],\n",
    "        'sprite_x': 0,\n",
    "        'sprite_y': 3\n",
    "    },\n",
    "    {\n",
    "        'sprite': [\n",
    "            [1,1,1],\n",
    "            [0,1,0],\n",
    "            [0,1,0]\n",
    "        ],\n",
    "        'sprite_x': 3,\n",
    "        'sprite_y': 3\n",
    "    }\n",
    "]\n",
    "\n",
    "def class_descriptions_to_class_pics():\n",
    "    class_pics = []\n",
    "    for i, desc in enumerate(class_descriptions):\n",
    "        if i >= num_classes:\n",
    "            break\n",
    "        pic = np.zeros((image_size, image_size), dtype=np.float32)\n",
    "        for dx in range(3):\n",
    "            for dy in range(3):\n",
    "                if desc['sprite'][dy][dx] == 1:\n",
    "                    pic[desc['sprite_y'] + dy, desc['sprite_x'] + dx] = 1.0\n",
    "        class_pics.append(pic)\n",
    "    return class_pics\n",
    "\n",
    "class_pics = class_descriptions_to_class_pics()\n",
    "# print(class_pics)\n",
    "\n",
    "def print_images(titles, images):\n",
    "    plt.figure(1)\n",
    "    num_figures = len(images)\n",
    "    for i, image in enumerate(images):\n",
    "        image_size = image.shape[0]\n",
    "        image_min = np.min(image)\n",
    "        image_max = np.max(image)\n",
    "        image_min = -1\n",
    "        image_max = 2\n",
    "        image_range = image_max - image_min\n",
    "        image = np.maximum(image_min, image)\n",
    "        image = np.minimum(image_max, image)\n",
    "        image = (image - image_min) / image_range\n",
    "        image_rgb = np.zeros((image_size, image_size, 3), dtype=np.float32)\n",
    "        image_rgb[:,:,0] = image\n",
    "        image_rgb[:,:,1] = image\n",
    "        image_rgb[:,:,2] = image\n",
    "        plt.subplot(1, num_figures, i + 1)\n",
    "        plt.imshow(image_rgb, interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "        if titles[i] is not None:\n",
    "            plt.title(titles[i])\n",
    "    plt.show()\n",
    "\n",
    "def draw_samples(N, class_pics):\n",
    "    samples = []\n",
    "    ground_truth_Z = np.zeros((N, num_classes), dtype=np.int8)\n",
    "    samples_to_print = set(np.random.choice(N, (num_samples_to_print,), replace=False))\n",
    "    for n in range(N):\n",
    "        image = np.zeros((image_size, image_size), dtype=np.float32)\n",
    "        features = np.random.choice(2, size=(num_classes,))\n",
    "        ground_truth_Z[n] = features\n",
    "#         print(features)\n",
    "        for k, v in enumerate(features):\n",
    "            if v == 1:\n",
    "                image += class_pics[k]\n",
    "        image_orig = np.copy(image)\n",
    "#         print_image(image)\n",
    "\n",
    "        noise = np.random.randn(image_size, image_size).astype(np.float32) * sigma_X\n",
    "#         print_image(noise)\n",
    "\n",
    "        image += noise\n",
    "        if n in samples_to_print:\n",
    "#             print(n)\n",
    "            print_images(['orig', 'noise', 'noised image'], [image_orig, noise, image])\n",
    "\n",
    "        samples.append(image)\n",
    "    return samples, ground_truth_Z\n",
    "\n",
    "samples, ground_truth_Z = draw_samples(N, class_pics)\n",
    "# print('ground_truth_Z\\n', ground_truth_Z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Z_columns = []\n",
    "column = np.random.choice(2, (N,))\n",
    "Z_columns.append(column)\n",
    "K_plus = len(Z_columns)\n",
    "# print(Z_columns)\n",
    "M = []\n",
    "M.append(np.sum(Z_columns[0]))\n",
    "# print('M', M)\n",
    "\n",
    "sigma_A = 0.5\n",
    "sigma_X = 1.7\n",
    "alpha = 1.0\n",
    "\n",
    "for it in range(10):\n",
    "    for n in range(N):\n",
    "        k = 0\n",
    "        while k < len(Z_columns):\n",
    "            column = Z_columns[k]\n",
    "            m = M[k]\n",
    "            if m == 1 and column[n] == 1:\n",
    "                # means that m_{-i} is zero\n",
    "                # so, delete the column\n",
    "                del Z_columns[k]\n",
    "                del M[k]\n",
    "                k -= 1\n",
    "            else:\n",
    "                # M_{-i} > 0\n",
    "                # what do we do now???\n",
    "                pass\n",
    "\n",
    "            k += 1\n",
    "\n",
    "# note that this code block wont do anything useful :-)  I abandoned it.\n",
    "# A new one, based on this, is much lower down this page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interlude: accelerated gibbs sampling\n",
    "\n",
    "At this point, I looked at the tutorial's equation 22.  But there's a proportional-to sign, $\\propto$.  How to handle this?  Since I'm not trying to do this research from scratch, just reproduce/understand the existing research, I reached out to Mr Google, to look for more explanations.  I found the following video, from Finale Doshi-Velez, which I'm going to interlude out to now.  The interlude is at: [accelerated_gibbs_samplings.ipynb](accelerated_gibbs_sampling.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration on 6x6 images, revisited\n",
    "\n",
    "### Challenge: sampling from non-normalized distribution?\n",
    "\n",
    "From reaching out to Doshi-Velez's presentation, it looks like we can sample a distribution that is only provided in proportionality, as long as it has a shape, which is well-defined, that we know how to sample from, ie typically a Gaussian.  There are probably other ways of handling other distributions, but a Gaussian should be reasonably straightforward to sample from, if we can get the distribution in that form.  Let's reach right back to the first section, and see what distribution(s) we need to sample from.\n",
    "\n",
    "Equation 22 from the Griffiths and Ghahramani tutorial states:\n",
    "\n",
    "$$\n",
    "P(z_{ik} \\mid \\mathbf{X}, \\mathbf{Z}_{-(i,k)}, \\sigma_X, \\sigma_A)\n",
    "\\propto\n",
    "p(\\mathbf{X} \\mid \\mathbf{Z}, \\sigma_X, \\sigma_A)\n",
    "\\,\n",
    "P(z_{ik} \\mid \\mathbf{z}_{-i,k})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first term of this equation, ie the likelihood of $\\mathbf{X}$, given the latent variables, and the hyper-parameters, is a Gaussian.  For the finite model, $P(z_{ik} \\mid \\mathbf{Z}_{-i,k})$ is given by equation 17 in the tutorial:\n",
    "\n",
    "$$\n",
    "P(z_{ik} = 1 \\mid \\mathbf{z}_{-i,k})\n",
    "= \\frac{m_{-i,k} + \\frac{\\alpha}{K}}\n",
    "  {N + \\frac{\\alpha}{K}}\n",
    "$$\n",
    "\n",
    "This seems not to be a Gaussian.  How to sample from the product of a Gaussian and this term?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interlude: is the product of two normalized distributions also normalized?\n",
    "\n",
    "Brainstorming a bit, we could sample from the Gaussian, which we could normalize first, and then multiply by $p(z_{ik} = 1 \\mid \\mathbf{z}_{-i,k})$.  Is it fair to say that the product of two normalized probability functions will be normalized?  Probably not, eg we could have the following two distributions:\n",
    "\n",
    "$$\n",
    "f(x) = 1\n",
    "\\mathrm{\\,when\\,} x \\ge 0 \\mathrm{\\,and\\,} x \\le 1 \\\\ \n",
    "= 0 \\mathrm{\\, otherwise}\n",
    "$$\n",
    "\n",
    "(which integrates to 1), and:\n",
    "\n",
    "$$\n",
    "g(x) = 1\n",
    "\\mathrm{\\,when\\,} x \\ge 2 \\mathrm{\\,and\\,} x \\le 3 \\\\ \n",
    "= 0 \\mathrm{\\, otherwise}\n",
    "$$\n",
    "\n",
    "... which integrates to 1 too.  But their product integrates to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate the un-normalized distribution over $z_{ik}$?\n",
    "\n",
    "Actually, the equation for the probaiblty of $z_{ik} = 1$ is not actually a probability distribution: it's the value of this probaiblity for one specific value of $z_{ik}$, ie $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try integrating over $c \\cdot p(\\mathbf{X} \\mid \\mathbf{Z}, \\sigma_X, \\sigma_A) \\cdot P(z_{ik} \\mid \\mathbf{z}_{-i,k})$ $z_{ik}$, using a probability distribution of $z_{ik}$, rather than just one specific value, and where $c$ is a constant of normalization, that will make the integrant integrate to $1$.\n",
    "\n",
    "$$\n",
    "\\int\n",
    "c\n",
    "\\cdot\n",
    "P(\\mathbf{X} \\mid \\mathbf{Z}, \\sigma_X, \\sigma_A)\n",
    "\\cdot\n",
    "P(z_{ik})\n",
    "\\,\n",
    "dz_{ik}\n",
    "$$\n",
    "\n",
    "And since $z_{ik}$ is discrete, ie $z_{ik} \\in \\{0, 1\\}$, then we can rewrite the integral as a sum:\n",
    "\n",
    "$$\n",
    "=\n",
    "c\n",
    "\\sum_{z_{ik}=0}^1\n",
    "\\left(\n",
    "    P(\\mathbf{X} \\mid \\mathbf{Z}, \\sigma_X, \\sigma_A)\n",
    "    \\cdot\n",
    "    P(z_{ik})\n",
    "\\right)\n",
    "$$\n",
    "&nbsp;\n",
    "\n",
    "$$\n",
    "=\n",
    "c\n",
    "\\sum_{z_{ik}=0}^1\n",
    "\\left(\n",
    "    \\mathcal{N}(\\mathbf{X}; \\mu_{\\mathbf{Z}, \\sigma_A, \\sigma_X}, \\Sigma_{\\mathbf{Z}, \\sigma_A, \\sigma_X})\n",
    "    \\cdot\n",
    "    P(z_{ik})\n",
    "\\right)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it seems like maybe we can simply calculate the value of the gaussian, for $z_{ik} \\in \\{0, 1\\}$, and multiply by $P(z_{ik} \\mid \\mathbf{z}_{-i,k})$, each time; and then normalize the sum of these two products?  Just to imagine this a bit, let's say we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "p_X_given_Z = [0.03, 0.02]  # pretend Gaussian samples, not normalized\n",
    "p_zik_given_Z_minus = [0.8, 0.2]  # normalized, sum to 1.0\n",
    "\n",
    "#Then\n",
    "p_zik_given_X_Z = [0] * 2\n",
    "for zik in [0, 1]:\n",
    "    p_zik_given_X_Z[zik] = p_X_given_Z[zik] * p_zik_given_Z_minus[zik]\n",
    "\n",
    "print(p_zik_given_X_Z)\n",
    "\n",
    "# normalize\n",
    "p_zik_given_X_Z /= np.sum(p_zik_given_X_Z)\n",
    "print('normalized p_zik_given_X_Z', p_zik_given_X_Z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the normalized values, with this toy data, are influenced by both the likelihood, and by the prior.\n",
    "\n",
    "Let's run with this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving for expected A\n",
    "\n",
    "We have:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[\\mathbf{A}] = (\\mathbf{Z}^T\\mathbf{Z} + \\frac{\\sigma_X^2}{\\sigma_A^2}\\mathbf{I})^{-1}\\mathbf{Z}^T\\mathbf{X}\n",
    "$$\n",
    "\n",
    "It'd be good to avoid that inverse.  Can we avoid it using a solver?  The numpy solver, [numpy.linalg.solve](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.solve.html#numpy.linalg.solve) solves equations in the form:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\mathbf{X} = \\mathbf{B}\n",
    "$$\n",
    "\n",
    "So, let's put the equation in $\\mathbb{E}[\\mathbf{A}]$ above into this form:\n",
    "\n",
    "$$\n",
    "(\\mathbf{Z}^T\\mathbf{Z} + \\frac{\\sigma_X^2}{\\sigma_A^2}\\mathbf{I})\\mathbb{E}[\\mathbf{A}] = \\mathbf{Z}^T\\mathbf{X}\n",
    "$$\n",
    "\n",
    "So, using $\\mathrm{\\backslash}$ to denote \"solve\", we have:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[\\mathbf{A}] = \\mathbf{Z}^T\\mathbf{X} \\mathrm{\\,\\backslash\\,} (\\mathbf{Z}^T\\mathbf{Z} + \\frac{\\sigma_X^2}{\\sigma_A^2}\\mathbf{I})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "Z_columns = []\n",
    "column = np.random.choice(2, (N,))\n",
    "Z_columns.append(column)\n",
    "K_plus = len(Z_columns)\n",
    "# print(Z_columns)\n",
    "M = []\n",
    "M.append(np.sum(Z_columns[0]))\n",
    "# print('M', M)\n",
    "\n",
    "sigma_A = 1.0\n",
    "sigma_X = 0.5\n",
    "alpha = 1.0\n",
    "\n",
    "\n",
    "def columns_to_array(columns):\n",
    "    if len(columns) == 0:\n",
    "        return None\n",
    "    rows = columns[0].shape[0]\n",
    "    cols = len(columns)\n",
    "    array = np.zeros((rows, cols), dtype=np.float32)\n",
    "    for col, column in enumerate(columns):\n",
    "        array[:, col] = column\n",
    "    return array\n",
    "\n",
    "\n",
    "def calc_log_p_X_given_Z(Z_columns, X, sigma_X, sigma_A):\n",
    "    Z = columns_to_array(Z_columns)\n",
    "#     print('Z', Z)\n",
    "    ZTZI = Z.T.dot(Z) + (sigma_X * sigma_X / sigma_A / sigma_A) * np.identity(Z.shape[1])\n",
    "#     print('ZTZI', ZTZI)\n",
    "    ZTZIInv = np.linalg.inv(ZTZI)\n",
    "#     print('ZTZIInv', ZTZIInv)\n",
    "    IZZZIZ = np.identity(Z.shape[0]) - Z.dot(ZTZIInv).dot(Z.T)\n",
    "#     print('IZZZIZ\\n', IZZZIZ)\n",
    "    XT___X = X.T.dot(IZZZIZ).dot(X)\n",
    "#     print('XT___X\\n', XT___X)\n",
    "    trace_term = np.trace(XT___X)\n",
    "#     print('trace_term', trace_term)\n",
    "    exponent = - 1 / (sigma_X * sigma_X * 2) * trace_term\n",
    "#     print('exponent', exponent)\n",
    "    return exponent\n",
    "#     gaussian_unnorm = np.exp(exponent)\n",
    "#     print('gaussian prob [%s]' % gaussian_unnorm)\n",
    "#     return gaussian_unnorm\n",
    "\n",
    "\n",
    "def calc_A(Z_columns, sigma_X, sigma_A):\n",
    "    Z = columns_to_array(Z_columns)\n",
    "    I = sigma_X * sigma_X / (sigma_A * sigma_A) * np.identity(Z.shape[1])\n",
    "    ZTZI = Z.T.dot(Z) + I\n",
    "#     print('ZTZI', ZTZI)\n",
    "    ZTZIInv = np.linalg.inv(ZTZI)\n",
    "#     print('ZTZIInv', ZTZIInv)\n",
    "    E_A = ZTZIInv.dot(Z.T).dot(X)\n",
    "#     print('E_A\\n', E_A)\n",
    "#     print('E_A.shape', E_A.shape)\n",
    "    image_titles = []\n",
    "    images = []\n",
    "    for k in range(E_A.shape[0]):\n",
    "        image_flat = E_A[k]\n",
    "        image = image_flat.reshape(image_size, image_size)\n",
    "        image_titles.append(None)\n",
    "        images.append(image)\n",
    "#         print_images(['A k=%s' % k], [image])\n",
    "#     asdf\n",
    "    print_images(image_titles, images)\n",
    "    return E_A\n",
    "\n",
    "\n",
    "def samples_to_X(samples):\n",
    "    N = len(samples)\n",
    "    X_features = samples[0].shape[0] * samples[0].shape[1]\n",
    "    X = np.zeros((N, X_features), dtype=np.float32)\n",
    "    for n, sample in enumerate(samples):\n",
    "        X[n] = sample.reshape(X_features)\n",
    "    return X\n",
    "\n",
    "\n",
    "X = samples_to_X(samples)\n",
    "print('X.shape', X.shape)\n",
    "# print('X\\n', X)\n",
    "# print('ground truth Z\\n', ground_truth_Z)\n",
    "np.set_printoptions(suppress=False, precision=3)\n",
    "num_its = 100\n",
    "for it in range(num_its):\n",
    "    num_added = 0\n",
    "    num_removed = 0\n",
    "    for n in range(N):\n",
    "        k = 0\n",
    "        while k < len(Z_columns):\n",
    "            old_zik = Z_columns[k][n]\n",
    "            if old_zik == 1:\n",
    "                m_minusi_k = M[k] - 1\n",
    "            else:\n",
    "                m_minusi_k = M[k]\n",
    "            if m_minusi_k > 0:\n",
    "                # get the probabilty of z_ik given Z_minus_ik, for\n",
    "                # zik = 0 and zik = 1\n",
    "                p_zik_given_Zminus = np.zeros((2,), dtype=np.float32)\n",
    "                p_zik_given_Zminus[1] = m_minusi_k / N\n",
    "                p_zik_given_Zminus[0] = 1.0 - p_zik_given_Zminus[1]\n",
    "                \n",
    "                # and we need also to get the probability from the gaussian, again\n",
    "                # for zik=0 and zik=1\n",
    "                # for now, lets just stupidly calculate it, not do rank-1s or anything\n",
    "\n",
    "                # calculate as log first, then normalize this first, then\n",
    "                # exp it, to avoid crazily tiny values etc\n",
    "                log_p_X_given_Z = np.zeros((2,), dtype=np.float32)\n",
    "                for zik in [0, 1]:\n",
    "                    Z_columns[k][n] = zik\n",
    "                    # add epsilon to it, to avoid nans\n",
    "                    log_p_X_given_Z[zik] = calc_log_p_X_given_Z(Z_columns, X, sigma_X, sigma_A)\n",
    "#                 print('log_p_X_given_Z', log_p_X_given_Z)\n",
    "                log_p_X_given_Z -= np.min(log_p_X_given_Z)\n",
    "#                 print('log_p_X_given_Z norm', log_p_X_given_Z)\n",
    "                p_X_given_Z = np.exp(log_p_X_given_Z)\n",
    "#                 print('p_X_given_Z', p_X_given_Z)\n",
    "                \n",
    "#                 print('p_zik_given_Zminus', p_zik_given_Zminus)\n",
    "#                 print('p_X_given_Z\\n', p_X_given_Z)\n",
    "                p_zik_given_X_Z_unnorm = np.multiply(\n",
    "                    p_zik_given_Zminus, p_X_given_Z)\n",
    "                p_zik_given_X_Z = p_zik_given_X_Z_unnorm / np.sum(p_zik_given_X_Z_unnorm)\n",
    "#                 print('p_zik_given_X_Z', p_zik_given_X_Z)\n",
    "\n",
    "                prob_zik_one = p_zik_given_X_Z[1]\n",
    "\n",
    "                p = random.uniform(0, 1)\n",
    "                new_zik = 1 if p <= prob_zik_one else 0\n",
    "                Z_columns[k][n] = new_zik\n",
    "                M[k] += new_zik - old_zik\n",
    "            else:\n",
    "                del M[k]\n",
    "                del Z_columns[k]\n",
    "                num_removed += 1\n",
    "                k -= 1\n",
    "\n",
    "            k += 1\n",
    "        # add new features\n",
    "        num_new_features = np.random.poisson(alpha / N)\n",
    "        for j in range(num_new_features):\n",
    "            M.append(1)\n",
    "            new_col = np.zeros((N,), dtype=np.float32)\n",
    "            new_col[n] = 1\n",
    "            Z_columns.append(new_col)\n",
    "            num_added += 1\n",
    "\n",
    "    if (it + 1) % (num_its // 10) == 0:\n",
    "        print('it %s' % (it + 1))\n",
    "#         print(columns_to_array(Z_columns))\n",
    "        expected_A = calc_A(Z_columns, sigma_X, sigma_A)\n",
    "#         print('expected_A\\n', expected_A)\n",
    "#     print('Z_columns', Z_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
