{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional expression for one latent element\n",
    "\n",
    "For Gibbs sampling, we need the conditional probability of one latent element $z_{i,k}$, conditional on the other latent elements, and also on the observed data values.\n",
    "\n",
    "ie, we need:\n",
    "\n",
    "$$\n",
    "P(z_{i,k} \\mid \\mathbf{X}, \\mathbf{Z}_{-(i,k)}, \\sigma_X, \\sigma_A)\n",
    "$$\n",
    "\n",
    "Note that since we are marginalizing over $\\mathbf{A}$, there is no $\\mathbf{A}$ in this expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Bayes Rules, the conditional probability for $z_{i,k}$ is:\n",
    "\n",
    "$$\n",
    "P(z_{i,k} | \\mathbf{X}, \\mathbf{Z}_{-(i,k)}, \\sigma_X, \\sigma_A)\n",
    "=\n",
    "\\frac\n",
    "  {P(\\mathbf{Z}_{-(i,k)} \\mid z_{i,k}, \\mathbf{X}, \\sigma_X, \\sigma_A)\\,P(z_{i,k} \\mid \\mathbf{X}, \\sigma_X, \\sigma_A)}\n",
    "  {P(\\mathbf{Z}_{-(i,k)} \\mid \\mathbf{X}, \\sigma_X, \\sigma_A)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "=\n",
    "\\frac\n",
    "  {P(\\mathbf{Z}_{-(i,k)} \\mid z_{i,k}, \\mathbf{X}, \\sigma_X, \\sigma_A)\\,P(z_{i,k})}\n",
    "  {P(\\mathbf{Z}_{-(i,k)}}\n",
    "$$\n",
    "\n",
    "or, we can try slightly differently:\n",
    "\n",
    "$$\n",
    "P(z_{i,k} | \\mathbf{X}, \\mathbf{Z}_{-(i,k)}, \\sigma_X, \\sigma_A)\n",
    "=\n",
    "\\frac\n",
    "  {P(\\mathbf{X} \\mid z_{i,k}, \\mathbf{Z}_{-(i,k)}, \\mathbf{X}, \\sigma_X, \\sigma_A)\\,P(z_{i,k} \\mid \\mathbf{Z}_{-(i,k)},\\sigma_X, \\sigma_A)}\n",
    "  {P(\\mathbf{X} \\mid \\mathbf{Z}_{-(i,k)}, \\sigma_X, \\sigma_A)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "=\n",
    "\\frac\n",
    "  {P(\\mathbf{X} \\mid \\mathbf{Z}, \\mathbf{X}, \\sigma_X, \\sigma_A)\\,P(z_{i,k} \\mid \\mathbf{Z}_{-(i,k)},\\sigma_X, \\sigma_A)}\n",
    "  {P(\\mathbf{X} \\mid \\mathbf{Z}_{-(i,k)}, \\sigma_X, \\sigma_A)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\propto P(\\mathbf{X} \\mid \\mathbf{Z}, \\mathbf{X}, \\sigma_X, \\sigma_A)\\,P(z_{i,k} \\mid \\mathbf{Z}_{-(i,k)},\\sigma_X, \\sigma_A)\n",
    "$$\n",
    "\n",
    "(since the denominator is constant wrt $z_{i,k}$, therefore doesnt change the shape of the probability distribution of $z_{i,k}$, simply acts as a constant of normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(\\mathbf{X} \\mid \\mathbf{X}, \\sigma_X, \\sigma_A)$, we've just calculated, by marginalizing the joint probability of $\\mathbf{X}$ and $\\mathbf{A}$ over $\\mathbf{A}$.\n",
    "\n",
    "$P(z_{i,k} \\mid \\mathbf{Z}_{-(i,k)})$, we calculated in the previous section, for Gibbs sampling of a finite feature model:\n",
    "\n",
    "$$\n",
    "P(z_{i,k} \\mid \\mathbf{z}_{-i,k})\n",
    "= \\frac{m_{-i,k} + \\frac{\\alpha}{K}}\n",
    "  {N + \\frac{\\alpha}{K}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interlude: rank-1 updates\n",
    "\n",
    "The formula for the exponential trace expression of the marginalized form over $\\mathbf{A}$ needs the calculation of an inverse:\n",
    "\n",
    "$$\n",
    "\\left(\n",
    "  \\mathbf{Z}^T\\mathbf{Z}\n",
    "  + \\frac{\\sigma_X^2}{\\sigma_A^2}\n",
    "  \\mathbf{I}\n",
    "\\right)^{-1}\n",
    "$$\n",
    "\n",
    "Matrix inversions are generally expensive, computationally. For example, if a matrix is symmetric and positive-definite, one can use Cholesky Decomposition to calculate the inverse, which uses about $\\frac{1}{3}n^3$ flops, where $n$ is the size of the matrix.  This is less than LU decomposition, which uses about $\\frac{2}{3}n^3$ flops, but is still cubic in $n$.\n",
    "\n",
    "Therefore if we can avoid re-calculating an inverse repeatedly during an algorithmic implementation, then the implementation will run faster.\n",
    "\n",
    "One way to avoid calculating the inverse repeatedly, is to use rank-1 updates, where this is possible.\n",
    "\n",
    "Given the Cholesky decomposition of matrix $\\mathbf{A}$ into $\\mathbf{L}\\mathbf{L}^T$, where $\\mathbf{L}$ is a lower triangular matrix, then the rank-1 update calculates $\\mathbf{L}'$ where:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} + \\mathbf{x}\\mathbf{x}^T\n",
    "= \\mathbf{L}' \\mathbf{L}'^T\n",
    "$$\n",
    "\n",
    "...given vector $\\mathbf{x}$, and the original decomposition of $\\mathbf{A} = \\mathbf{L}\\mathbf{L}^T$\n",
    "\n",
    "Per \"Methods for Modifying Matrix Factorizations\", by Gill et al, 1974, rank-1 update to Cholesky factorization can be carried out in $O(n^2)$ flops. (method 'C1').\n",
    "\n",
    "From a practical, engineering, point of view, it looks like numpy doesnt provide an implementation for rank-1 updates.  LINPACK does, and matlab does, but numpy doesnt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Wikipedia](https://en.wikipedia.org/wiki/Cholesky_decomposition) provides a matlab implementation of a rank-1 update.  Let's try implementing it in Python, and then try a `numpy` built-in method (which presumably uses BLAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 3000)\n",
      "[[ 2970.41996429    21.31644394]\n",
      " [   21.31644394  2942.49052004]]\n",
      "time for full rank Cholesky 0.3525505065917969 seconds\n",
      "[[ 54.50155928   0.           0.        ]\n",
      " [  0.39111622  54.243318     0.        ]\n",
      " [  0.93970653   0.2525172   54.49271706]]\n",
      "(3000,)\n",
      "[-0.14441793  0.18327688 -1.23138222]\n",
      "3007.10831474\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e08ed7b840d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mLLT2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mdiff\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "N = 3000\n",
    "B = np.random.randn(N, N)\n",
    "A = B.T.dot(B)\n",
    "print(A.shape)\n",
    "print(A[:2,:2])\n",
    "start = time.time()\n",
    "L = np.linalg.cholesky(A)\n",
    "print('time for full rank Cholesky %s seconds' % (time.time() - start))\n",
    "print(L[:3,:3])\n",
    "\n",
    "# check\n",
    "LLT = L.dot(L.T)\n",
    "assert np.abs(A - LLT).max() < 1e-6\n",
    "\n",
    "x = np.random.randn(N)\n",
    "print(x.shape)\n",
    "print(x[:3])\n",
    "\n",
    "def update_cholesky(L, x):\n",
    "    N = x.shape[0]\n",
    "    for k in range(N):\n",
    "        r = math.sqrt(L[k, k] * L[k, k] + x[k] * x[k])\n",
    "        c = r / L[k, k]\n",
    "        s = x[k] / L[k, k]\n",
    "        L[k, k] = r\n",
    "        L[k + 1:, k] = (L[k + 1:, k] + s * x[k + 1:]) / c\n",
    "        x[k + 1:] = c * x[k + 1:] - s * L[k + 1:, k]\n",
    "\n",
    "update_cholesky(L, x)\n",
    "LLT2 = L.dot(L.T)\n",
    "diff = np.abs(A + x.dot(x.T) - LLT2).max()\n",
    "print(diff)\n",
    "assert diff < 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... fails, not sure why.  But anyway, looking at the Griffiths and Ghahramani tutorial again, it looks like it's not actually using a generic rank-1 Cholesky update: they're designing/deriving their own rank-1 update formulae.  So let's go through that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rank-1 updates to marginal probability of $\\mathbf{X}$\n",
    "\n",
    "Reminder: $\\mathbf{M}$ is:\n",
    "\n",
    "$$\\mathbf{M}\n",
    "= \\left(\n",
    "  \\mathbf{Z}^T\\mathbf{Z} + \\frac{\\alpha_X^2}{\\alpha_A^2}\n",
    "  \\mathbf{I}\n",
    "\\right)^{-1}\n",
    "$$\n",
    "\n",
    "Per the tutorial, we should define:\n",
    "\n",
    "$$\n",
    "\\mathbf{M}_{-i}\n",
    "= \\left(\n",
    "\\sum_{j \\ne i}\n",
    "z_j^T z_j\n",
    "+ \\frac{\\sigma_X^2}{\\sigma_A^2}\\mathbf{I}\n",
    "\\right)\n",
    "^{-1}\n",
    "$$\n",
    "\n",
    "And then, I cant quite guess/see what the tutorial is/is going to do, so I'm just going to work through what the tutorial does:\n",
    "\n",
    "$$\n",
    "\\mathbf{M}_{-i}\n",
    "= (\\mathbf{M}^{-1} - \\mathbf{z}_i^T\\mathbf{z}_i)^{-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= ( \\dots\n",
    "$$\n",
    "\n",
    "I stared at this for a while, and then decided the tutorial must probably be using a generic, well-known, rank-1 update formula.  I googled for 'matrix inverse rank-1 update', and found:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Sherman%E2%80%93Morrison_formula\n",
    "\n",
    "This gives the following formula:\n",
    "\n",
    "$$\n",
    "\\left(\n",
    "  \\mathbf{A} + \\mathbf{u}\\mathbf{v}^T \n",
    "\\right)^{-1}\n",
    "=\n",
    "\\mathbf{A}^{-1}\n",
    "-\n",
    "\\frac{\\mathbf{A}^{-1}\\mathbf{u}\\mathbf{v}^T\\mathbf{A}^{-1}}\n",
    "  {1 + \\mathbf{v}^T\\mathbf{A}^{-1}\\mathbf{u}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty similar to equation (23) in the tutorial, so let's work with the idea that the tutorial is using the Sherman-Morrison formula for now.  Let's first modify the Sherman-Morrison formula in two ways:\n",
    "\n",
    "- write it for a downdate, ie for $(\\mathbf{A} - \\dots)^{-1}$ rather than $(\\mathbf{A} + \\dots)^{-1}$, and\n",
    "- modify to write for the case that there is only one vector $\\mathbf{v}$, rather than the more general form of two unequal vectors $\\mathbf{u}$ and $\\mathbf{v}$\n",
    "\n",
    "We can do this by substituting $\\mathbf{u} = - \\mathbf{v}$:\n",
    "\n",
    "$$\n",
    "(\\mathbf{A} - \\mathbf{v}\\mathbf{v}^T)^{-1}\n",
    "=\n",
    "\\mathbf{A}^{-1}\n",
    "-\n",
    "\\frac\n",
    "  {\\mathbf{A}^{-1} \\cdot (-\\mathbf{v}) \\cdot \\mathbf{v}^T \\cdot \\mathbf{A}^{-1}}\n",
    "  {1 + \\mathbf{v}^T \\cdot \\mathbf{A}^{-1} \\cdot (-\\mathbf{v})}\n",
    "$$\n",
    "\n",
    "$$\n",
    "=\n",
    "\\mathbf{A}^{-1}\n",
    "+\n",
    "\\frac\n",
    "  {\\mathbf{A}^{-1} \\cdot (\\mathbf{v}) \\cdot \\mathbf{v}^T \\cdot \\mathbf{A}^{-1}}\n",
    "  {1 - \\mathbf{v}^T \\cdot \\mathbf{A}^{-1} \\cdot (\\mathbf{v})}\n",
    "$$\n",
    "\n",
    "Or, by comparison with what is in the tutorial, giving some idea of where this might be going, reversing the order of the terms in the denominator, and the sign of the right-hand side:\n",
    "\n",
    "$$\n",
    "=\n",
    "\\mathbf{A}^{-1}\n",
    "-\n",
    "\\frac\n",
    "  {\\mathbf{A}^{-1} \\cdot (\\mathbf{v}) \\cdot \\mathbf{v}^T \\cdot \\mathbf{A}^{-1}}\n",
    "  {\\mathbf{v}^T \\cdot \\mathbf{A}^{-1} \\cdot (\\mathbf{v}) - 1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "=\n",
    "\\mathbf{A}^{-1}\n",
    "-\n",
    "\\frac\n",
    "  {\\mathbf{A}^{-1} \\mathbf{v} \\mathbf{v}^T \\mathbf{A}^{-1}}\n",
    "  {\\mathbf{v}^T \\mathbf{A}^{-1} \\mathbf{v} - 1}\n",
    "$$\n",
    "\n",
    "This kind of matches what's in the tutorial, except that we have inverses here, like $\\mathbf{A}^{-1}$, whereas the tutorial has $\\mathbf{M}$, but since $\\mathbf{M}$ is in fact defined as an inverse, ie $(\\mathbf{Z}^T\\mathbf{Z} - \\frac{\\alpha_X^2}{\\alpha_A^2}\\mathbf{I})^{-1}$, then this might work out.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's substitute in the terms/notation for our actual concrete expression, into the modified Sherman-Morrison formula.  This gives:\n",
    "\n",
    "$$\n",
    "\n",
    "$$\n",
    "\n",
    "If it was using the Sherman-Formula formula, then, using the tutorial's notation, we'd have:\n",
    "\n",
    "$$\n",
    "(\\mathbf{M}^{-1} - \\mathbf{z}_i^T \\mathbf{z}_i)^{-1}\n",
    "= \\mathbf{M}^{-1}\n",
    "+ \n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
