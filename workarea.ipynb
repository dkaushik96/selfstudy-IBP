{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional expression for one latent element\n",
    "\n",
    "For Gibbs sampling, we need the conditional probability of one latent element $z_{i,k}$, conditional on the other latent elements, and also on the observed data values.\n",
    "\n",
    "ie, we need:\n",
    "\n",
    "$$\n",
    "P(z_{i,k} \\mid \\mathbf{X}, \\mathbf{Z}_{-(i,k)}, \\sigma_X, \\sigma_A)\n",
    "$$\n",
    "\n",
    "Note that since we are marginalizing over $\\mathbf{A}$, there is no $\\mathbf{A}$ in this expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Bayes Rules, the conditional probability for $z_{i,k}$ is:\n",
    "\n",
    "$$\n",
    "P(z_{i,k} | \\mathbf{X}, \\mathbf{Z}_{-(i,k)}, \\sigma_X, \\sigma_A)\n",
    "=\n",
    "\\frac\n",
    "  {P(\\mathbf{Z}_{-(i,k)} \\mid z_{i,k}, \\mathbf{X}, \\sigma_X, \\sigma_A)\\,P(z_{i,k} \\mid \\mathbf{X}, \\sigma_X, \\sigma_A)}\n",
    "  {P(\\mathbf{Z}_{-(i,k)} \\mid \\mathbf{X}, \\sigma_X, \\sigma_A)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "=\n",
    "\\frac\n",
    "  {P(\\mathbf{Z}_{-(i,k)} \\mid z_{i,k}, \\mathbf{X}, \\sigma_X, \\sigma_A)\\,P(z_{i,k})}\n",
    "  {P(\\mathbf{Z}_{-(i,k)}}\n",
    "$$\n",
    "\n",
    "or, we can try slightly differently:\n",
    "\n",
    "$$\n",
    "P(z_{i,k} | \\mathbf{X}, \\mathbf{Z}_{-(i,k)}, \\sigma_X, \\sigma_A)\n",
    "=\n",
    "\\frac\n",
    "  {P(\\mathbf{X} \\mid z_{i,k}, \\mathbf{Z}_{-(i,k)}, \\mathbf{X}, \\sigma_X, \\sigma_A)\\,P(z_{i,k} \\mid \\mathbf{Z}_{-(i,k)},\\sigma_X, \\sigma_A)}\n",
    "  {P(\\mathbf{X} \\mid \\mathbf{Z}_{-(i,k)}, \\sigma_X, \\sigma_A)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "=\n",
    "\\frac\n",
    "  {P(\\mathbf{X} \\mid \\mathbf{Z}, \\mathbf{X}, \\sigma_X, \\sigma_A)\\,P(z_{i,k} \\mid \\mathbf{Z}_{-(i,k)},\\sigma_X, \\sigma_A)}\n",
    "  {P(\\mathbf{X} \\mid \\mathbf{Z}_{-(i,k)}, \\sigma_X, \\sigma_A)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\propto P(\\mathbf{X} \\mid \\mathbf{Z}, \\mathbf{X}, \\sigma_X, \\sigma_A)\\,P(z_{i,k} \\mid \\mathbf{Z}_{-(i,k)},\\sigma_X, \\sigma_A)\n",
    "$$\n",
    "\n",
    "(since the denominator is constant wrt $z_{i,k}$, therefore doesnt change the shape of the probability distribution of $z_{i,k}$, simply acts as a constant of normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(\\mathbf{X} \\mid \\mathbf{X}, \\sigma_X, \\sigma_A)$, we've just calculated, by marginalizing the joint probability of $\\mathbf{X}$ and $\\mathbf{A}$ over $\\mathbf{A}$.\n",
    "\n",
    "$P(z_{i,k} \\mid \\mathbf{Z}_{-(i,k)})$, we calculated in the previous section, for Gibbs sampling of a finite feature model:\n",
    "\n",
    "$$\n",
    "P(z_{i,k} \\mid \\mathbf{z}_{-i,k})\n",
    "= \\frac{m_{-i,k} + \\frac{\\alpha}{K}}\n",
    "  {N + \\frac{\\alpha}{K}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interlude: rank-1 updates\n",
    "\n",
    "The formula for the exponential trace expression of the marginalized form over $\\mathbf{A}$ needs the calculation of an inverse:\n",
    "\n",
    "$$\n",
    "\\left(\n",
    "  \\mathbf{Z}^T\\mathbf{Z}\n",
    "  + \\frac{\\sigma_X^2}{\\sigma_A^2}\n",
    "  \\mathbf{I}\n",
    "\\right)^{-1}\n",
    "$$\n",
    "\n",
    "Matrix inversions are generally expensive, computationally. For example, if a matrix is symmetric and positive-definite, one can use Cholesky Decomposition to calculate the inverse, which uses about $\\frac{1}{3}n^3$ flops, where $n$ is the size of the matrix.  This is less than LU decomposition, which uses about $\\frac{2}{3}n^3$ flops, but is still cubic in $n$.\n",
    "\n",
    "Therefore if we can avoid re-calculating an inverse repeatedly during an algorithmic implementation, then the implementation will run faster.\n",
    "\n",
    "One way to avoid calculating the inverse repeatedly, is to use rank-1 updates, where this is possible.\n",
    "\n",
    "Given the Cholesky decomposition of matrix $\\mathbf{A}$ into $\\mathbf{L}\\mathbf{L}^T$, where $\\mathbf{L}$ is a lower triangular matrix, then the rank-1 update calculates $\\mathbf{L}'$ where:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} + \\mathbf{x}\\mathbf{x}^T\n",
    "= \\mathbf{L}' \\mathbf{L}'^T\n",
    "$$\n",
    "\n",
    "...given vector $\\mathbf{x}$, and the original decomposition of $\\mathbf{A} = \\mathbf{L}\\mathbf{L}^T$\n",
    "\n",
    "Per \"Methods for Modifying Matrix Factorizations\", by Gill et al, 1974, rank-1 update to Cholesky factorization can be carried out in $O(n^2)$ flops. (method 'C1').\n",
    "\n",
    "From a practical, engineering, point of view, it looks like numpy doesnt provide an implementation for rank-1 updates.  LINPACK does, and matlab does, but numpy doesnt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Wikipedia](https://en.wikipedia.org/wiki/Cholesky_decomposition) provides a matlab implementation of a rank-1 update.  Let's try implementing it in Python, and then try a `numpy` built-in method (which presumably uses BLAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 3000)\n",
      "[[ 2970.41996429    21.31644394]\n",
      " [   21.31644394  2942.49052004]]\n",
      "time for full rank Cholesky 0.3525505065917969 seconds\n",
      "[[ 54.50155928   0.           0.        ]\n",
      " [  0.39111622  54.243318     0.        ]\n",
      " [  0.93970653   0.2525172   54.49271706]]\n",
      "(3000,)\n",
      "[-0.14441793  0.18327688 -1.23138222]\n",
      "3007.10831474\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e08ed7b840d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mLLT2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mdiff\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "N = 3000\n",
    "B = np.random.randn(N, N)\n",
    "A = B.T.dot(B)\n",
    "print(A.shape)\n",
    "print(A[:2,:2])\n",
    "start = time.time()\n",
    "L = np.linalg.cholesky(A)\n",
    "print('time for full rank Cholesky %s seconds' % (time.time() - start))\n",
    "print(L[:3,:3])\n",
    "\n",
    "# check\n",
    "LLT = L.dot(L.T)\n",
    "assert np.abs(A - LLT).max() < 1e-6\n",
    "\n",
    "x = np.random.randn(N)\n",
    "print(x.shape)\n",
    "print(x[:3])\n",
    "\n",
    "def update_cholesky(L, x):\n",
    "    N = x.shape[0]\n",
    "    for k in range(N):\n",
    "        r = math.sqrt(L[k, k] * L[k, k] + x[k] * x[k])\n",
    "        c = r / L[k, k]\n",
    "        s = x[k] / L[k, k]\n",
    "        L[k, k] = r\n",
    "        L[k + 1:, k] = (L[k + 1:, k] + s * x[k + 1:]) / c\n",
    "        x[k + 1:] = c * x[k + 1:] - s * L[k + 1:, k]\n",
    "\n",
    "update_cholesky(L, x)\n",
    "LLT2 = L.dot(L.T)\n",
    "diff = np.abs(A + x.dot(x.T) - LLT2).max()\n",
    "print(diff)\n",
    "assert diff < 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... fails, not sure why.  But anyway, looking at the Griffiths and Ghahramani tutorial again, it looks like it's not actually using a generic rank-1 Cholesky update: they're designing/deriving their own rank-1 update formulae.  So let's go through that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rank-1 updates to marginal probability of $\\mathbf{X}$\n",
    "\n",
    "Reminder: $\\mathbf{M}$ is:\n",
    "\n",
    "$$\\mathbf{M}\n",
    "= \\left(\n",
    "  \\mathbf{Z}^T\\mathbf{Z} + \\frac{\\alpha_X^2}{\\alpha_A^2}\n",
    "  \\mathbf{I}\n",
    "\\right)^{-1}\n",
    "$$\n",
    "\n",
    "Per the tutorial, we should define:\n",
    "\n",
    "$$\n",
    "\\mathbf{M}_{-i}\n",
    "= \\left(\n",
    "\\sum_{j \\ne i}\n",
    "z_j^T z_j\n",
    "+ \\frac{\\sigma_X^2}{\\sigma_A^2}\\mathbf{I}\n",
    "\\right)\n",
    "^{-1}\n",
    "$$\n",
    "\n",
    "And then, I cant quite guess/see what the tutorial is/is going to do, so I'm just going to work through what the tutorial does:\n",
    "\n",
    "$$\n",
    "\\mathbf{M}_{-i}\n",
    "= (\\mathbf{M}^{-1} - \\mathbf{z}_i^T\\mathbf{z}_i)^{-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= ( \\dots\n",
    "$$\n",
    "\n",
    "### Sheman-Morrison Formula for rank-1 updates\n",
    "\n",
    "I stared at this for a while, and then decided the tutorial must probably be using a generic, well-known, rank-1 update formula.  I googled for 'matrix inverse rank-1 update', and found:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Sherman%E2%80%93Morrison_formula\n",
    "\n",
    "This gives the following formula:\n",
    "\n",
    "$$\n",
    "\\left(\n",
    "  \\mathbf{A} + \\mathbf{u}\\mathbf{v}^T \n",
    "\\right)^{-1}\n",
    "=\n",
    "\\mathbf{A}^{-1}\n",
    "-\n",
    "\\frac{\\mathbf{A}^{-1}\\mathbf{u}\\mathbf{v}^T\\mathbf{A}^{-1}}\n",
    "  {1 + \\mathbf{v}^T\\mathbf{A}^{-1}\\mathbf{u}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty similar to equation (23) in the tutorial, so let's work with the idea that the tutorial is using the Sherman-Morrison formula for now.  Let's first modify the Sherman-Morrison formula in two ways:\n",
    "\n",
    "- write it for a downdate, ie for $(\\mathbf{A} - \\dots)^{-1}$ rather than $(\\mathbf{A} + \\dots)^{-1}$, and\n",
    "- modify to write for the case that there is only one vector $\\mathbf{v}$, rather than the more general form of two unequal vectors $\\mathbf{u}$ and $\\mathbf{v}$\n",
    "\n",
    "We can do this by substituting $\\mathbf{u} = - \\mathbf{v}$:\n",
    "\n",
    "$$\n",
    "(\\mathbf{A} - \\mathbf{v}\\mathbf{v}^T)^{-1}\n",
    "=\n",
    "\\mathbf{A}^{-1}\n",
    "-\n",
    "\\frac\n",
    "  {\\mathbf{A}^{-1} \\cdot (-\\mathbf{v}) \\cdot \\mathbf{v}^T \\cdot \\mathbf{A}^{-1}}\n",
    "  {1 + \\mathbf{v}^T \\cdot \\mathbf{A}^{-1} \\cdot (-\\mathbf{v})}\n",
    "$$\n",
    "\n",
    "$$\n",
    "=\n",
    "\\mathbf{A}^{-1}\n",
    "+\n",
    "\\frac\n",
    "  {\\mathbf{A}^{-1} \\cdot (\\mathbf{v}) \\cdot \\mathbf{v}^T \\cdot \\mathbf{A}^{-1}}\n",
    "  {1 - \\mathbf{v}^T \\cdot \\mathbf{A}^{-1} \\cdot (\\mathbf{v})}\n",
    "$$\n",
    "\n",
    "Or, by comparison with what is in the tutorial, giving some idea of where this might be going, reversing the order of the terms in the denominator, and the sign of the right-hand side:\n",
    "\n",
    "$$\n",
    "=\n",
    "\\mathbf{A}^{-1}\n",
    "-\n",
    "\\frac\n",
    "  {\\mathbf{A}^{-1} \\cdot (\\mathbf{v}) \\cdot \\mathbf{v}^T \\cdot \\mathbf{A}^{-1}}\n",
    "  {\\mathbf{v}^T \\cdot \\mathbf{A}^{-1} \\cdot (\\mathbf{v}) - 1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "=\n",
    "\\mathbf{A}^{-1}\n",
    "-\n",
    "\\frac\n",
    "  {\\mathbf{A}^{-1} \\mathbf{v} \\mathbf{v}^T \\mathbf{A}^{-1}}\n",
    "  {\\mathbf{v}^T \\mathbf{A}^{-1} \\mathbf{v} - 1}\n",
    "$$\n",
    "\n",
    "This kind of matches what's in the tutorial, except that we have inverses here, like $\\mathbf{A}^{-1}$, whereas the tutorial has $\\mathbf{M}$, but since $\\mathbf{M}$ is in fact defined as an inverse, ie $(\\mathbf{Z}^T\\mathbf{Z} - \\frac{\\alpha_X^2}{\\alpha_A^2}\\mathbf{I})^{-1}$, then this might work out.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's substitute in the terms/notation for our actual concrete expression, into the modified Sherman-Morrison formula.  This means we will subsitute $\\mathbf{A}$ by $\\mathbf{M}^{-1}$, and $\\mathbf{v}$ with $\\mathbf{z}_i^T$.  Note that $\\mathbf{v}$ is a column vector, whereas $\\mathbf{z}_i$ is a row vector.  $\\mathbf{z}_i^T$ is a column vector, which matches therefore the form of $\\mathbf{v}$.  So we get:\n",
    "\n",
    "$$\n",
    "(\\mathbf{M}^{-1} - \\mathbf{z}_i^T\\mathbf{z})^{-1}\n",
    "=\n",
    "\\mathbf{M}\n",
    "-\n",
    "\\frac{\\mathbf{M}\\mathbf{z}_i^T\\mathbf{z}_i \\mathbf{M}}\n",
    "  {\\mathbf{z}_i\\mathbf{M}\\mathbf{z}_i^T - 1}\n",
    "$$\n",
    "\n",
    "... which matches exactly the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Sherman-Morrison in numpy\n",
    "\n",
    "Let's retry rank-1 updates in numpy, using the Sherman-Morrison formula.  Note that the Sherman-Morrison formula doesnt need decomposition, eg QR or Cholesky, just needs the inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 3000)\n",
      "[[ 2982.31866914    96.38717338]\n",
      " [   96.38717338  3039.32098946]]\n",
      "time for full rank inverse 2.2654874324798584 seconds\n",
      "[[ 1.36423992 -0.47994222  0.13859518]\n",
      " [-0.47994222  0.30385504 -0.01174672]\n",
      " [ 0.13859518 -0.01174672  0.33828845]]\n",
      "6.32098817732e-11\n",
      "(3000, 1)\n",
      "[[-1.22683011]\n",
      " [ 1.1851708 ]\n",
      " [ 0.35445188]]\n",
      "time for sherman morrison 1.4911704063415527 seconds\n",
      "diff after rank 1 update: 0.312939937953\n",
      "time for full rank inverse 2.178471326828003 seconds\n",
      "diff after full rank inverse 2.45563569479e-11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "N = 3000\n",
    "B = np.random.randn(N, N)\n",
    "A = B.T.dot(B)\n",
    "print(A.shape)\n",
    "print(A[:2,:2])\n",
    "start = time.time()\n",
    "Ainv = np.linalg.inv(A)\n",
    "print('time for full rank inverse %s seconds' % (time.time() - start))\n",
    "print(Ainv[:3,:3])\n",
    "\n",
    "# check\n",
    "A_Ainv = A.dot(Ainv)\n",
    "diff = np.abs(A_Ainv - np.identity(N)).max()\n",
    "print(diff)\n",
    "assert diff < 1e-8\n",
    "\n",
    "x = np.random.randn(N, 1)\n",
    "print(x.shape)\n",
    "print(x[:3])\n",
    "\n",
    "def sherman_morrison(Ainv, x):\n",
    "    numerator = Ainv.dot(x).dot(x.T).dot(Ainv)\n",
    "    denominator = x.T.dot(Ainv).dot(x) - 1\n",
    "    return Ainv - numerator / denominator\n",
    "\n",
    "start = time.time()\n",
    "Ainv2 = sherman_morrison(Ainv, x)\n",
    "print('time for sherman morrison %s seconds' % (time.time() - start))\n",
    "A2 = A + x.dot(x.T)\n",
    "A2_Ainv2 = A2.dot(Ainv2)\n",
    "diff = np.abs(A2_Ainv2 - np.identity(N)).max()\n",
    "print('diff after rank 1 update: %s' % diff)\n",
    "# assert diff < 1e-8\n",
    "\n",
    "# try full rank inverse\n",
    "start = time.time()\n",
    "Ainv2 = np.linalg.inv(A2)\n",
    "print('time for full rank inverse %s seconds' % (time.time() - start))\n",
    "A2_Ainv2 = A2.dot(Ainv2)\n",
    "diff = np.abs(A2_Ainv2 - np.identity(N)).max()\n",
    "print('diff after full rank inverse %s' % diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmmm, Sherman-Morrison took only 40% less time than full-rank, but vastly more inaccurate.\n",
    "\n",
    "But ... what if we re-arrange the order of the matrix multiplication slightly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for sherman morrison 0.23725247383117676 seconds\n",
      "diff after rank 1 update: 0.312939937938\n",
      "time for full rank inverse 2.1450388431549072 seconds\n",
      "diff after full rank inverse 2.45563569479e-11\n"
     ]
    }
   ],
   "source": [
    "def sherman_morrison_v2(Ainv, x):\n",
    "    n1 = Ainv.dot(x)\n",
    "    n2 = x.T.dot(Ainv)\n",
    "    numerator = n1.dot(n2)\n",
    "    denominator = x.T.dot(Ainv).dot(x) - 1\n",
    "    return Ainv - numerator / denominator\n",
    "\n",
    "start = time.time()\n",
    "Ainv2 = sherman_morrison_v2(Ainv, x)\n",
    "print('time for sherman morrison %s seconds' % (time.time() - start))\n",
    "A2 = A + x.dot(x.T)\n",
    "A2_Ainv2 = A2.dot(Ainv2)\n",
    "diff = np.abs(A2_Ainv2 - np.identity(N)).max()\n",
    "print('diff after rank 1 update: %s' % diff)\n",
    "# assert diff < 1e-8\n",
    "\n",
    "# try full rank inverse\n",
    "start = time.time()\n",
    "Ainv2 = np.linalg.inv(A2)\n",
    "print('time for full rank inverse %s seconds' % (time.time() - start))\n",
    "A2_Ainv2 = A2.dot(Ainv2)\n",
    "diff = np.abs(A2_Ainv2 - np.identity(N)).max()\n",
    "print('diff after full rank inverse %s' % diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better: still looking pretty inaccurate, compared to full-rank, but at least it's ~10 times faster, for matrices with side $3000$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading the section entitled 'Application' on the wikipedia page, which describes the assymptotic complexity, it occurred to me that `n1` and `n2` are basically the same matrix, so we can do:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for sherman morrison 0.2752869129180908 seconds\n",
      "diff after rank 1 update: 0.312939914919\n",
      "time for full rank inverse 2.1179018020629883 seconds\n",
      "diff after full rank inverse 2.45563569479e-11\n"
     ]
    }
   ],
   "source": [
    "def sherman_morrison_v3(Ainv, x):\n",
    "    n1 = Ainv.dot(x)\n",
    "    numerator = n1.dot(n1.T)\n",
    "    denominator = x.T.dot(Ainv).dot(x) - 1\n",
    "    return Ainv - numerator / denominator\n",
    "\n",
    "start = time.time()\n",
    "Ainv2 = sherman_morrison_v3(Ainv, x)\n",
    "print('time for sherman morrison %s seconds' % (time.time() - start))\n",
    "A2 = A + x.dot(x.T)\n",
    "A2_Ainv2 = A2.dot(Ainv2)\n",
    "diff = np.abs(A2_Ainv2 - np.identity(N)).max()\n",
    "print('diff after rank 1 update: %s' % diff)\n",
    "# assert diff < 1e-8\n",
    "\n",
    "# try full rank inverse\n",
    "start = time.time()\n",
    "Ainv2 = np.linalg.inv(A2)\n",
    "print('time for full rank inverse %s seconds' % (time.time() - start))\n",
    "A2_Ainv2 = A2.dot(Ainv2)\n",
    "diff = np.abs(A2_Ainv2 - np.identity(N)).max()\n",
    "print('diff after full rank inverse %s' % diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...but the time is the same.  So presumably the time is dominated by the `n1.dot(n1.T)` calculation.  Check this point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for n1 0.0075109004974365234\n",
      "time for numerator 0.052231788635253906\n",
      "time for denominator 0.010253190994262695\n",
      "time for final per-element 0.06621360778808594\n",
      "time for sherman morrison 0.138261079788208 seconds\n",
      "diff after rank 1 update: 0.312939914919\n"
     ]
    }
   ],
   "source": [
    "def sherman_morrison_with_timing(Ainv, x):\n",
    "    last = time.time()\n",
    "    n1 = Ainv.dot(x)\n",
    "    print('time for n1 %s' % (time.time() - last))\n",
    "    last = time.time()\n",
    "    numerator = n1.dot(n1.T)\n",
    "    print('time for numerator %s' % (time.time() - last))\n",
    "    last = time.time()\n",
    "    denominator = x.T.dot(Ainv).dot(x) - 1\n",
    "    print('time for denominator %s' % (time.time() - last))\n",
    "    last = time.time()\n",
    "    res = Ainv - numerator / denominator\n",
    "    print('time for final per-element %s' % (time.time() - last))\n",
    "    return res\n",
    "\n",
    "start = time.time()\n",
    "Ainv2 = sherman_morrison_with_timing(Ainv, x)\n",
    "print('time for sherman morrison %s seconds' % (time.time() - start))\n",
    "A2_Ainv2 = A2.dot(Ainv2)\n",
    "diff = np.abs(A2_Ainv2 - np.identity(N)).max()\n",
    "print('diff after rank 1 update: %s' % diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dominated by the final per-element operations, interestingly.  And surprisingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this because the per-element scalar division is being implemented using division, rather than as multiplication by 1 over the divisor?  Check this point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for n1 0.008286476135253906\n",
      "time for numerator 0.07381415367126465\n",
      "time for denominator 0.011293649673461914\n",
      "time for final per-element 0.12431550025939941\n",
      "time for sherman morrison 0.2201707363128662 seconds\n",
      "diff after rank 1 update: 0.312939914921\n"
     ]
    }
   ],
   "source": [
    "def sherman_morrison_with_timing_v2(Ainv, x):\n",
    "    last = time.time()\n",
    "    n1 = Ainv.dot(x)\n",
    "    print('time for n1 %s' % (time.time() - last))\n",
    "    last = time.time()\n",
    "    numerator = n1.dot(n1.T)\n",
    "    print('time for numerator %s' % (time.time() - last))\n",
    "    last = time.time()\n",
    "    denominator = x.T.dot(Ainv).dot(x) - 1\n",
    "    print('time for denominator %s' % (time.time() - last))\n",
    "    last = time.time()\n",
    "    res = Ainv - numerator * (1 / denominator)\n",
    "    print('time for final per-element %s' % (time.time() - last))\n",
    "    return res\n",
    "\n",
    "start = time.time()\n",
    "Ainv2 = sherman_morrison_with_timing_v2(Ainv, x)\n",
    "print('time for sherman morrison %s seconds' % (time.time() - start))\n",
    "A2_Ainv2 = A2.dot(Ainv2)\n",
    "diff = np.abs(A2_Ainv2 - np.identity(N)).max()\n",
    "print('diff after rank 1 update: %s' % diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse. bizarrely.  It's almost as though the operations are being executed asynchonously, and the final operation is a sync point.  It is surprising for per-element operations to take relatively significant time.\n",
    "\n",
    "Is it something like, the `denominator` value is a matrix, and somehow this makes it take longer?  Let's convert it to a scalar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for n1 0.009202003479003906\n",
      "time for numerator 0.05918169021606445\n",
      "time for denominator 0.008460283279418945\n",
      "time for final per-element 0.06301307678222656\n",
      "time for sherman morrison 0.14108610153198242 seconds\n",
      "diff after rank 1 update: 0.312939914921\n"
     ]
    }
   ],
   "source": [
    "def sherman_morrison_with_timing_v2(Ainv, x):\n",
    "    last = time.time()\n",
    "    n1 = Ainv.dot(x)\n",
    "    print('time for n1 %s' % (time.time() - last))\n",
    "    last = time.time()\n",
    "    numerator = n1.dot(n1.T)\n",
    "    print('time for numerator %s' % (time.time() - last))\n",
    "    last = time.time()\n",
    "    denominator = x.T.dot(Ainv).dot(x) - 1\n",
    "    print('time for denominator %s' % (time.time() - last))\n",
    "    last = time.time()\n",
    "    res = Ainv - numerator * (1 / denominator.item())\n",
    "    print('time for final per-element %s' % (time.time() - last))\n",
    "    return res\n",
    "\n",
    "start = time.time()\n",
    "Ainv2 = sherman_morrison_with_timing_v2(Ainv, x)\n",
    "print('time for sherman morrison %s seconds' % (time.time() - start))\n",
    "A2_Ainv2 = A2.dot(Ainv2)\n",
    "diff = np.abs(A2_Ainv2 - np.identity(N)).max()\n",
    "print('diff after rank 1 update: %s' % diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weirdly, making the denominator explicitly a scalar accelerates the per-element operations by 50%, and now the matrix multiplication of the numerator dominates.\n",
    "\n",
    "The Sherman-Morrison update is now about ~15 times faster than the full-rank inverse, though still just as imprecise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
