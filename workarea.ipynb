{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration on 6x6 images, revisited\n",
    "\n",
    "### Challenge: sampling from non-normalized distribution?\n",
    "\n",
    "From reaching out to Doshi-Velez's presentation, it looks like we can sample a distribution that is only provided in proportionality, as long as it has a shape, which is well-defined, that we know how to sample from, ie typically a Gaussian.  There are probably other ways of handling other distributions, but a Gaussian should be reasonably straightforward to sample from, if we can get the distribution in that form.  Let's reach right back to the first section, and see what distribution(s) we need to sample from.\n",
    "\n",
    "Equation 22 from the Griffiths and Ghahramani tutorial states:\n",
    "\n",
    "$$\n",
    "P(z_{ik} \\mid \\mathbf{X}, \\mathbf{Z}_{-(i,k)}, \\sigma_X, \\sigma_A)\n",
    "\\propto\n",
    "p(\\mathbf{X} \\mid \\mathbf{Z}, \\sigma_X, \\sigma_A)\n",
    "\\,\n",
    "P(z_{ik} \\mid \\mathbf{z}_{-i,k})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first term of this equation, ie the likelihood of $\\mathbf{X}$, given the latent variables, and the hyper-parameters, is a Gaussian.  For the finite model, $P(z_{ik} \\mid \\mathbf{Z}_{-i,k})$ is given by equation 17 in the tutorial:\n",
    "\n",
    "$$\n",
    "P(z_{ik} = 1 \\mid \\mathbf{z}_{-i,k})\n",
    "= \\frac{m_{-i,k} + \\frac{\\alpha}{K}}\n",
    "  {N + \\frac{\\alpha}{K}}\n",
    "$$\n",
    "\n",
    "This seems not to be a Gaussian.  How to sample from the product of a Gaussian and this term?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interlude: is the product of two normalized distributions also normalized?\n",
    "\n",
    "Brainstorming a bit, we could sample from the Gaussian, which we could normalize first, and then multiply by $p(z_{ik} = 1 \\mid \\mathbf{z}_{-i,k})$.  Is it fair to say that the product of two normalized probability functions will be normalized?  Probably not, eg we could have the following two distributions:\n",
    "\n",
    "$$\n",
    "f(x) = 1\n",
    "\\mathrm{\\,when\\,} x \\ge 0 \\mathrm{\\,and\\,} x \\le 1 \\\\ \n",
    "= 0 \\mathrm{\\, otherwise}\n",
    "$$\n",
    "\n",
    "(which integrates to 1), and:\n",
    "\n",
    "$$\n",
    "g(x) = 1\n",
    "\\mathrm{\\,when\\,} x \\ge 2 \\mathrm{\\,and\\,} x \\le 3 \\\\ \n",
    "= 0 \\mathrm{\\, otherwise}\n",
    "$$\n",
    "\n",
    "... which integrates to 1 too.  But their product integrates to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate the un-normalized distribution over $z_{ik}$?\n",
    "\n",
    "Actually, the equation for the probaiblty of $z_{ik} = 1$ is not actually a probability distribution: it's the value of this probaiblity for one specific value of $z_{ik}$, ie $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try integrating over $c \\cdot p(\\mathbf{X} \\mid \\mathbf{Z}, \\sigma_X, \\sigma_A) \\cdot P(z_{ik} \\mid \\mathbf{z}_{-i,k})$ $z_{ik}$, using a probability distribution of $z_{ik}$, rather than just one specific value, and where $c$ is a constant of normalization, that will make the integrant integrate to $1$.\n",
    "\n",
    "$$\n",
    "\\int\n",
    "c\n",
    "\\cdot\n",
    "P(\\mathbf{X} \\mid \\mathbf{Z}, \\sigma_X, \\sigma_A)\n",
    "\\cdot\n",
    "P(z_{ik})\n",
    "\\,\n",
    "dz_{ik}\n",
    "$$\n",
    "\n",
    "And since $z_{ik}$ is discrete, ie $z_{ik} \\in \\{0, 1\\}$, then we can rewrite the integral as a sum:\n",
    "\n",
    "$$\n",
    "=\n",
    "c\n",
    "\\sum_{z_{ik}=0}^1\n",
    "\\left(\n",
    "    P(\\mathbf{X} \\mid \\mathbf{Z}, \\sigma_X, \\sigma_A)\n",
    "    \\cdot\n",
    "    P(z_{ik})\n",
    "\\right)\n",
    "$$\n",
    "&nbsp;\n",
    "\n",
    "$$\n",
    "=\n",
    "c\n",
    "\\sum_{z_{ik}=0}^1\n",
    "\\left(\n",
    "    \\mathcal{N}(\\mathbf{X}; \\mu_{\\mathbf{Z}, \\sigma_A, \\sigma_X}, \\Sigma_{\\mathbf{Z}, \\sigma_A, \\sigma_X})\n",
    "    \\cdot\n",
    "    P(z_{ik})\n",
    "\\right)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it seems like maybe we can simply calculate the value of the gaussian, for $z_{ik} \\in \\{0, 1\\}$, and multiply by $P(z_{ik} \\mid \\mathbf{z}_{-i,k})$, each time; and then normalize the sum of these two products?  Just to imagine this a bit, let's say we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.024, 0.004]\n",
      "normalized p_zik_given_X_Z [ 0.85714286  0.14285714]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "p_X_given_Z = [0.03, 0.02]  # pretend Gaussian samples, not normalized\n",
    "p_zik_given_Z_minus = [0.8, 0.2]  # normalized, sum to 1.0\n",
    "\n",
    "#Then\n",
    "p_zik_given_X_Z = [0] * 2\n",
    "for zik in [0, 1]:\n",
    "    p_zik_given_X_Z[zik] = p_X_given_Z[zik] * p_zik_given_Z_minus[zik]\n",
    "\n",
    "print(p_zik_given_X_Z)\n",
    "\n",
    "# normalize\n",
    "p_zik_given_X_Z /= np.sum(p_zik_given_X_Z)\n",
    "print('normalized p_zik_given_X_Z', p_zik_given_X_Z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the normalized values, with this toy data, are influenced by both the likelihood, and by the prior.\n",
    "\n",
    "Let's run with this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
